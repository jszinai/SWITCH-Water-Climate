{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c3fe84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.1.5-cp36-cp36m-macosx_10_9_x86_64.whl (10.2 MB)\n",
      "     |████████████████████████████████| 10.2 MB 6.4 MB/s            \n",
      "\u001b[?25hCollecting pyyaml\n",
      "  Downloading PyYAML-6.0-cp36-cp36m-macosx_10_9_x86_64.whl (189 kB)\n",
      "     |████████████████████████████████| 189 kB 4.1 MB/s            \n",
      "\u001b[?25hCollecting matplotlib\n",
      "  Downloading matplotlib-3.3.4-cp36-cp36m-macosx_10_9_x86_64.whl (8.5 MB)\n",
      "     |████████████████████████████████| 8.5 MB 4.5 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/site-packages (from pandas) (2.8.2)\n",
      "Collecting numpy>=1.15.4\n",
      "  Downloading numpy-1.19.5-cp36-cp36m-macosx_10_9_x86_64.whl (15.6 MB)\n",
      "     |████████████████████████████████| 15.6 MB 4.7 MB/s            \n",
      "\u001b[?25hCollecting pytz>=2017.2\n",
      "  Downloading pytz-2022.5-py2.py3-none-any.whl (500 kB)\n",
      "     |████████████████████████████████| 500 kB 4.6 MB/s            \n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.3.1-cp36-cp36m-macosx_10_9_x86_64.whl (61 kB)\n",
      "     |████████████████████████████████| 61 kB 580 kB/s            \n",
      "\u001b[?25hCollecting pillow>=6.2.0\n",
      "  Downloading Pillow-8.4.0-cp36-cp36m-macosx_10_10_x86_64.whl (3.0 MB)\n",
      "     |████████████████████████████████| 3.0 MB 123 kB/s            \n",
      "\u001b[?25hCollecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3\n",
      "  Downloading pyparsing-3.0.7-py3-none-any.whl (98 kB)\n",
      "     |████████████████████████████████| 98 kB 2.7 MB/s            \n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/juliaszinai/Library/Python/3.6/lib/python/site-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
      "Installing collected packages: pytz, pyparsing, pillow, numpy, kiwisolver, cycler, pyyaml, pandas, matplotlib\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33m  DEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\n",
      "Successfully installed cycler-0.11.0 kiwisolver-1.3.1 matplotlib-3.3.4 numpy-1.19.5 pandas-1.1.5 pillow-8.4.0 pyparsing-3.0.7 pytz-2022.5 pyyaml-6.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install pandas pyyaml matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2ee85b8-0950-47b3-bba8-f2318427426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import datetime as dt\n",
    "\n",
    "import os\n",
    "import pprint\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party packages\n",
    "from cycler import cycler\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import psycopg2 as pg\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import psycopg2.extras as extras\n",
    "\n",
    "\n",
    "#%load_ext lab_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ff9038-df8a-4d32-a368-1e95a769f61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_config():\n",
    "    \"\"\"Read the config.yaml configuration file\"\"\"\n",
    "    if not os.path.isfile(\"config.yaml\"):\n",
    "        raise Exception(\n",
    "            \"config.yaml does not exist. Try running 'switch new scenario' to auto-create it.\"\n",
    "        )\n",
    "    with open(\"config.yaml\") as f:\n",
    "        return yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "\n",
    "def load_dotenv():\n",
    "    try:\n",
    "        # Try to load environment variables from .env file using dotenv package.\n",
    "        # If package is not installed, nothing happens.\n",
    "        from dotenv import load_dotenv\n",
    "\n",
    "        load_dotenv()\n",
    "    except ModuleNotFoundError:\n",
    "        pass\n",
    "\n",
    "\n",
    "def connect(schema=\"switch\", connection_env_var=\"DB_URL\"):\n",
    "    \"\"\"Connects to the Postgres DB\n",
    "\n",
    "    This function uses the environment variables to get the URL to connect to the DB. Both\n",
    "    password and user should be passed directly on the URL for safety purposes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    schema: str Schema of the DB to look for tables. Default is switch\n",
    "    connection_env_var: The environment variable to use as the connection string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    conn: Database connection object from psycopg2\n",
    "    \"\"\"\n",
    "    # load_dotenv()\n",
    "    # db_url = os.getenv(connection_env_var)\n",
    "    db_url = \"\"\n",
    "    if db_url is None:\n",
    "        raise Exception(\n",
    "            f\"Please set the environment variable '{connection_env_var}' to the database URL.\"\n",
    "            \"The format is normally: postgresql://<user>:<password>@<host>:5432/<database>\"\n",
    "        )\n",
    "\n",
    "    conn = pg.connect(\n",
    "        db_url,\n",
    "        options=f\"-c search_path={schema}\",\n",
    "    )\n",
    "\n",
    "    if conn is None:\n",
    "        raise SystemExit(\n",
    "            \"Failed to connect to PostgreSQL database.\"\n",
    "            \"Ensure that the database url is correct, format should normally be:\"\n",
    "            \"postgresql://<user>:<password>@<host>:5432/<database>\"\n",
    "        )\n",
    "\n",
    "    # TODO: Send this to the logger\n",
    "    print(\"Connection established to PostgreSQL database.\")\n",
    "    return conn\n",
    "\n",
    "\n",
    "def get_load_data(\n",
    "    demand_scenario_id: int,\n",
    "    force_download=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    \"\"\"Query the load data from the database\"\"\"\n",
    "    fname = f\"load_data-{demand_scenario_id}.csv\"\n",
    "\n",
    "    if not os.path.exists(fname) or force_download:\n",
    "        df = read_from_db(\n",
    "            table_name=\"demand_timeseries\",\n",
    "            where_clause=f\"demand_scenario_id = '{demand_scenario_id}'\",\n",
    "            **kwargs,\n",
    "        )\n",
    "        df = df.sort_values([\"load_zone_id\", \"raw_timepoint_id\"])\n",
    "        df[\"date\"] = df[\"timestamp_utc\"].dt.strftime(\"%Y-%m-%d\").values\n",
    "        df.to_csv(fname, index=False)\n",
    "    else:\n",
    "        df = pd.read_csv(fname, parse_dates=[\"timestamp_utc\"])\n",
    "    return df\n",
    "\n",
    "\n",
    "def insert_to_db(\n",
    "    table_name: str,\n",
    "    columns: list,\n",
    "    values,\n",
    "    db_conn,\n",
    "    schema,\n",
    "    id_column=None,\n",
    "    id_var=None,\n",
    "    overwrite=False,\n",
    "    verbose=None,\n",
    "    **kwargs,\n",
    "):\n",
    "    # Safety check if no DB connection is passed\n",
    "    if not db_conn:\n",
    "        raise SystemExit(\n",
    "            \"No connection to DB provided. Check if you passed it correctly\"\n",
    "        )\n",
    "    # Convert columns to a single string to pass it into the query\n",
    "    columns = \",\".join(columns)\n",
    "\n",
    "    # Default queries.\n",
    "    # NOTE: We can add new queries on this section\n",
    "    search_query = f\"\"\"\n",
    "        select {id_column} from {schema}.{table_name} where {id_column} = {id_var};\n",
    "    \"\"\"\n",
    "    default_query = f\"\"\"\n",
    "        insert into {schema}.{table_name}({columns}) values %s;\n",
    "    \"\"\"\n",
    "    clear_query = f\"\"\"\n",
    "        delete from {schema}.{table_name} where {id_column} = {id_var};\n",
    "    \"\"\"\n",
    "\n",
    "    print(f\"+ {table_name}: \")\n",
    "\n",
    "    # Start transaction with DB\n",
    "    with db_conn as conn:\n",
    "        with conn.cursor() as curs:\n",
    "\n",
    "            # Check if ID is in database\n",
    "            curs.execute(search_query)\n",
    "            data = curs.fetchall()\n",
    "\n",
    "            if data and overwrite:\n",
    "                if verbose:\n",
    "                    print(data)\n",
    "                    print(values)\n",
    "                print(\"|  Data exists. Overwritting data\")\n",
    "                curs.execute(clear_query)\n",
    "                extras.execute_values(curs, default_query, values)\n",
    "            elif not data:\n",
    "                print(\"|  Inserting new data to DB.\")\n",
    "                if verbose:\n",
    "                    print(values)\n",
    "                extras.execute_values(curs, default_query, values)\n",
    "            else:\n",
    "                raise SystemExit(\n",
    "                    f\"\\nValue {id_var} for {id_column} already exists on table {table_name}. Use another one.\"\n",
    "                )\n",
    "    ...\n",
    "\n",
    "\n",
    "def read_from_db(\n",
    "    table_name: str,\n",
    "    db_conn,\n",
    "    schema,\n",
    "    where_clause: str = None,\n",
    "    columns: list = None,\n",
    "    verbose=False,\n",
    "    **kwargs,\n",
    "):\n",
    "    if not db_conn:\n",
    "        raise SystemExit(\n",
    "            \"No connection to DB provided. Check if you passed it correctly\"\n",
    "        )\n",
    "\n",
    "    print(f\" | Reading from {table_name}\")\n",
    "\n",
    "    columns = \"*\" if columns is None else \",\".join(columns)\n",
    "    query = f\"\"\"\n",
    "        SELECT {columns}\n",
    "        FROM {schema}.{table_name}\n",
    "        \"\"\"\n",
    "    if where_clause is not None:\n",
    "        query += f\" WHERE {where_clause}\"\n",
    "    query += \";\"\n",
    "\n",
    "    if verbose:\n",
    "        print(query)\n",
    "\n",
    "    return pd.read_sql_query(query, db_conn)\n",
    "\n",
    "\n",
    "def get_peak_days(data, freq: str = \"MS\", verbose: bool = False):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Get timestamp of monthly peak\n",
    "    df = df.set_index(\"timestamp_utc\")\n",
    "    peak_idx = df.groupby(pd.Grouper(freq=\"MS\")).idxmax()[\"demand_mw\"]\n",
    "\n",
    "    # Get date of peak timestamp\n",
    "    datetime_idx = pd.to_datetime(peak_idx.values).strftime(\"%Y-%m-%d\").values\n",
    "\n",
    "    # Get all days where monthly peak demand is observed\n",
    "    # peak_days = df.loc[df.date.isin(datetime_idx)]\n",
    "\n",
    "    # Return dataframe with peak days with hourly resolution\n",
    "    return datetime_idx\n",
    "\n",
    "\n",
    "def read_config(fname: str, verbose=None) -> dict:\n",
    "    \"\"\"Read yaml configuration file\"\"\"\n",
    "\n",
    "    fpath = pathlib.Path(fname)\n",
    "\n",
    "    full_path = project_path / fpath\n",
    "\n",
    "    # Load yaml file with full loader\n",
    "    with open(full_path) as f:\n",
    "        config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "    if verbose:\n",
    "        pprint.pprint(config)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    return Path(\".\").parent.parent\n",
    "\n",
    "\n",
    "project_path = get_project_root()\n",
    "data_path = project_path / \"data/raw\"\n",
    "fig_path = project_path / \"figs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26176e0-44f4-411e-8e31-097cf3828f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCHEMA = \"switch\"\n",
    "OVERWRITE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "942c95d8-6b0a-47ae-a62b-5c877c23ad72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection established to PostgreSQL database.\n"
     ]
    }
   ],
   "source": [
    "# Start db\n",
    "db_conn = connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e0dbb25-283f-4fcd-8819-768308e75a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_timepoint_id</th>\n",
       "      <th>raw_timeseries_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-03 08:00:00</th>\n",
       "      <td>8816</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 09:00:00</th>\n",
       "      <td>8817</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 10:00:00</th>\n",
       "      <td>8818</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 11:00:00</th>\n",
       "      <td>8819</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-03 12:00:00</th>\n",
       "      <td>8820</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     raw_timepoint_id  raw_timeseries_id\n",
       "timestamp_utc                                           \n",
       "2011-01-03 08:00:00              8816                  1\n",
       "2011-01-03 09:00:00              8817                  1\n",
       "2011-01-03 10:00:00              8818                  1\n",
       "2011-01-03 11:00:00              8819                  1\n",
       "2011-01-03 12:00:00              8820                  1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = f\"\"\"SELECT * from switch.raw_timepoint;\"\"\"\n",
    "raw_tps = pd.read_sql_query(query, db_conn).set_index(\"timestamp_utc\")\n",
    "raw_tps.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa68821d-1b02-4d5c-b1a2-2906cdaab9b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'demand_scenario': 174,\n",
      " 'periods': {2030: {'end_year': 2032, 'length': 5, 'start_year': 2028},\n",
      "             2035: {'end_year': 2037, 'length': 5, 'start_year': 2033},\n",
      "             2040: {'end_year': 2042, 'length': 5, 'start_year': 2038},\n",
      "             2045: {'end_year': 2047, 'length': 5, 'start_year': 2043},\n",
      "             2050: {'end_year': 2052, 'length': 5, 'start_year': 2048}},\n",
      " 'sampling': {'description': 'Peak + median day per month with 24-hrs '\n",
      "                             'resolution for CESM1-CAM5_rcp85 climate '\n",
      "                             'scenario.\\n',\n",
      "              'id': 38,\n",
      "              'method': 'M1',\n",
      "              'name': 'P+M+24hr+CESM1-CAM5_rcp85',\n",
      "              'tps_per_day': 24},\n",
      " 'study_timeframe': {'description': '2030-2050 periods with 5 year length '\n",
      "                                    'each.\\n',\n",
      "                     'id': 39,\n",
      "                     'name': 2050}}\n"
     ]
    }
   ],
   "source": [
    "config = read_config(\"sampling.yaml\", verbose=True)\n",
    "\n",
    "study_timeframe_id = config[\"study_timeframe\"].get(\"id\")\n",
    "study_name = config[\"study_timeframe\"].get(\"name\")\n",
    "study_description = config[\"study_timeframe\"].get(\"description\")\n",
    "time_sample_id = config[\"sampling\"].get(\"id\")\n",
    "agg = config[\"sampling\"].get(\"agg\")\n",
    "ts_name = config[\"sampling\"].get(\"name\")\n",
    "method = config[\"sampling\"].get(\"method\")\n",
    "ts_description = config[\"sampling\"].get(\"description\")\n",
    "demand_scenario_id = config[\"demand_scenario\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6e99c3d-ccb5-4afc-bcd3-2b58311ab6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(39, 1, 2028, 2030, 5, 2032),\n",
       " (39, 2, 2033, 2035, 5, 2037),\n",
       " (39, 3, 2038, 2040, 5, 2042),\n",
       " (39, 4, 2043, 2045, 5, 2047),\n",
       " (39, 5, 2048, 2050, 5, 2052)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period_values = [\n",
    "    (\n",
    "        study_timeframe_id,\n",
    "        period_id + 1,\n",
    "        period_info[\"start_year\"],\n",
    "        period,\n",
    "        period_info[\"length\"],\n",
    "        period_info[\"end_year\"],\n",
    "    )\n",
    "    for period_id, (period, period_info) in enumerate(config[\"periods\"].items())\n",
    "]\n",
    "period_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c01d9bcd-413d-4426-91f6-7f8fa2c93db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of timepoints per day: 24 with 1 hours duration.\n"
     ]
    }
   ],
   "source": [
    "no_timepoints = config[\"sampling\"].get(\"tps_per_day\")\n",
    "# if no_timepoints != 6:\n",
    "#     raise NotImplementedError(\"Not yet implemented\")\n",
    "delta_t = int(24 / no_timepoints)\n",
    "print(f\"Number of timepoints per day: {no_timepoints} with {delta_t} hours duration.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11a72655-1a02-4b41-8572-edc594934c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 15340610 entries, 2016-01-01 08:00:00 to 2051-01-01 08:00:00\n",
      "Data columns (total 5 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   load_zone_id        int64  \n",
      " 1   demand_scenario_id  int64  \n",
      " 2   raw_timepoint_id    int64  \n",
      " 3   load_zone_name      object \n",
      " 4   demand_mw           float64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 702.2+ MB\n"
     ]
    }
   ],
   "source": [
    "fname = \"data/load_ts_174.csv\"\n",
    "df = pd.read_csv(\n",
    "    fname,\n",
    "    dtype={\n",
    "        \"load_zone_id\": \"int\",\n",
    "        \"demand_scenario_id\": \"int\",\n",
    "        \"load_zone_name\": \"str\",\n",
    "    },\n",
    "    parse_dates=[\"timestamp_utc\"],\n",
    "    usecols=np.r_[:6],\n",
    "    index_col=\"timestamp_utc\",\n",
    ")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37d5aa10-06d5-400a-9435-d64e0062a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[df.load_zone_name.str.startswith(\"CA_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f1dcf80-23eb-49ca-bee0-030e7161496d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_timepoint_id</th>\n",
       "      <th>demand_mw</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01 08:00:00</th>\n",
       "      <td>52592</td>\n",
       "      <td>-59.279918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 09:00:00</th>\n",
       "      <td>52593</td>\n",
       "      <td>84649.198473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 10:00:00</th>\n",
       "      <td>52594</td>\n",
       "      <td>81357.305873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 11:00:00</th>\n",
       "      <td>52595</td>\n",
       "      <td>79202.762673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-01 12:00:00</th>\n",
       "      <td>52596</td>\n",
       "      <td>78409.977273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051-01-01 04:00:00</th>\n",
       "      <td>359404</td>\n",
       "      <td>180179.990807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051-01-01 05:00:00</th>\n",
       "      <td>359405</td>\n",
       "      <td>192725.399907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051-01-01 06:00:00</th>\n",
       "      <td>359406</td>\n",
       "      <td>205990.926807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051-01-01 07:00:00</th>\n",
       "      <td>359407</td>\n",
       "      <td>187761.655007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2051-01-01 08:00:00</th>\n",
       "      <td>359408</td>\n",
       "      <td>88853.069866</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>306817 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     raw_timepoint_id      demand_mw\n",
       "timestamp_utc                                       \n",
       "2016-01-01 08:00:00             52592     -59.279918\n",
       "2016-01-01 09:00:00             52593   84649.198473\n",
       "2016-01-01 10:00:00             52594   81357.305873\n",
       "2016-01-01 11:00:00             52595   79202.762673\n",
       "2016-01-01 12:00:00             52596   78409.977273\n",
       "...                               ...            ...\n",
       "2051-01-01 04:00:00            359404  180179.990807\n",
       "2051-01-01 05:00:00            359405  192725.399907\n",
       "2051-01-01 06:00:00            359406  205990.926807\n",
       "2051-01-01 07:00:00            359407  187761.655007\n",
       "2051-01-01 08:00:00            359408   88853.069866\n",
       "\n",
       "[306817 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aggregate load by zone per timestamp\n",
    "#data_ca = df[df.load_zone_name.str.startswith(\"CA_\")].copy()\n",
    "# Aggregate load by zone per timestamp\n",
    "load_total = (\n",
    "    df.groupby([\"timestamp_utc\", \"raw_timepoint_id\"])[[\"demand_mw\"]]\n",
    "    .sum()\n",
    "    .reset_index(level=1)\n",
    ")\n",
    "load_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a12b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to pacific time\n",
    "load_total_pst = load_total.tz_localize('utc').tz_convert('US/pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9544fee9-cae2-4385-9e69-a385eb8685fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_peak_days(data, freq: str = \"MS\", verbose: bool = False):\n",
    "    df = data.copy()\n",
    "\n",
    "    # Get timestamp of monthly peak\n",
    "    peak_idx = df.groupby(pd.Grouper(freq=\"MS\")).idxmax()[\"demand_mw\"]\n",
    "\n",
    "    # Get date of peak timestamp\n",
    "    datetime_idx = pd.to_datetime(peak_idx.values).strftime(\"%Y-%m-%d\").values\n",
    "\n",
    "    df[\"date\"] = df.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get all days where monthly peak demand is observed\n",
    "    peak_days = df.loc[df.date.isin(datetime_idx)]\n",
    "\n",
    "    # Return dataframe with peak days with hourly resolution\n",
    "    return datetime_idx, peak_days\n",
    "\n",
    "\n",
    "def get_next_prv_day(date):\n",
    "    if not isinstance(date, pd.Timestamp):\n",
    "        date = pd.to_datetime(date)\n",
    "    prev_day = date + pd.Timedelta(value=-24, unit=\"hours\")\n",
    "    next_day = date + pd.Timedelta(value=24, unit=\"hours\")\n",
    "    return prev_day, next_day\n",
    "\n",
    "\n",
    "def get_median_days(data, freq: str = \"MS\", verbose: bool = False):\n",
    "    median_idx = []\n",
    "    df = data.copy()\n",
    "\n",
    "    for _, month_data in df.groupby([pd.Grouper(freq=\"AS\"), pd.Grouper(freq=\"MS\")]):\n",
    "        daily_mean = month_data.groupby(pd.Grouper(freq=\"D\"))[\"demand_mw\"].mean()\n",
    "\n",
    "        if len(daily_mean) & 1:\n",
    "            # If 31 days grab median location\n",
    "            index_median = daily_mean.loc[daily_mean == daily_mean.median()].index[0]\n",
    "        else:\n",
    "            # If 30 or 28 days calculate day closes to the median\n",
    "            # NOTE: It could be the case that there are two days with the same value.\n",
    "            # In that case... well...run.\n",
    "            index_median = (np.abs(daily_mean - daily_mean.median())).idxmin()\n",
    "        median_idx.append(index_median)\n",
    "\n",
    "    df[\"date\"] = df.index.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get date of median timestamp\n",
    "    median_idx = pd.to_datetime(median_idx).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Get all days where monthly peak demand is observed\n",
    "    median_days = df.loc[df.date.isin(median_idx)]\n",
    "    return median_idx, median_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b9bbfe-e477-4bf5-a6ff-34882458b75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_tps = []\n",
    "for row in period_values:\n",
    "    (study_id, period_id, start_year, label, scale_to_period, _end_year) = row\n",
    "    year_demand = load_total.loc[str(label)].copy()\n",
    "    peak_idx, peak_days = get_peak_days(year_demand)\n",
    "    median_idx, median_days = get_median_days(year_demand)\n",
    "    for peak_day in peak_idx:\n",
    "        prev_day, next_day = get_next_prv_day(peak_day)\n",
    "        subset = year_demand.loc[peak_day].copy()\n",
    "        # subset = year_demand.loc[prev_day:next_day].copy()\n",
    "        month = subset.index.month.unique()[0]\n",
    "        day = subset.index.day.unique()[0]\n",
    "        # subset_peak = subset[\"demand_mw\"].idxmax()\n",
    "        # lw_interval = subset_peak - pd.Timedelta(value=delta_t * 2, unit=\"hours\")\n",
    "        # up_interval = subset_peak + pd.Timedelta(\n",
    "        #     value=delta_t * 2 + delta_t, unit=\"hours\"\n",
    "        # )\n",
    "        # tps = year_demand[\n",
    "        #     subset_peak\n",
    "        #     - pd.Timedelta(value=delta_t * 2, unit=\"hours\") : subset_peak\n",
    "        #     + pd.Timedelta(value=(delta_t * 2 + delta_t), unit=\"hours\") : delta_t\n",
    "        # ].copy()  # raise KeyError(\"Odd number of timepoints\")\n",
    "        tps = year_demand[\n",
    "            peak_day\n",
    "        ].copy()  # raise KeyError(\"Odd number of timepoints\")\n",
    "        tps.loc[:, \"study_timeframe_id\"] = study_timeframe_id\n",
    "        tps.loc[:, \"time_sample_id\"] = time_sample_id\n",
    "        tps.loc[:, \"id_column\"] = f\"{label}-{month:>02}-{day:>02}_P\"\n",
    "        tps.loc[:, \"period_id\"] = period_id\n",
    "        sampled_tps.append(tps)\n",
    "    for median_day in median_idx:\n",
    "        prev_day, next_day = get_next_prv_day(median_day)\n",
    "        subset = year_demand.loc[median_day].copy()\n",
    "        month = subset.index.month.unique()[0]\n",
    "        day = subset.index.day.unique()[0]\n",
    "        tps = subset[::delta_t].copy()\n",
    "        tps.loc[:, \"study_timeframe_id\"] = study_timeframe_id\n",
    "        tps.loc[:, \"time_sample_id\"] = time_sample_id\n",
    "        tps.loc[:, \"id_column\"] = f\"{label}-{month:>02}-{day:>02}_M\"\n",
    "        tps.loc[\n",
    "            :, \"period_id\"\n",
    "        ] = period_id  # raise KeyError(\"Odd number of timepoints\")\n",
    "        sampled_tps.append(tps)\n",
    "sampled_tps = pd.concat(sampled_tps).sort_index().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ceb3655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset.index.month.unique()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a49d1db-ebf0-4431-9116-efe2579abaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add a new argument to identify groups of days.\n",
    "sampled_tps.loc[:, \"date\"] = sampled_tps.timestamp_utc.dt.strftime(\"%Y-%m-%d\").values\n",
    "sampled_tps.loc[:, \"days_in_month\"] = sampled_tps.timestamp_utc.dt.days_in_month\n",
    "sampled_tps[\"year\"] = sampled_tps.timestamp_utc.dt.year\n",
    "sampled_tps[\"leap_year\"] = sampled_tps[\"year\"] % 4\n",
    "sampled_tps[\"days_in_year\"] = np.where(sampled_tps[\"leap_year\"] == 0, 366, 365)\n",
    "# Get first timepoint for each date\n",
    "sampled_tps.loc[:, \"first_timepoint_utc\"] = sampled_tps.groupby(\"id_column\")[\n",
    "    \"timestamp_utc\"\n",
    "].transform(\"first\")\n",
    "\n",
    "# Get last timepoint for each date\n",
    "# FIXME: This might not work if peak is found in the transition between two dates.\n",
    "sampled_tps.loc[:, \"last_timepoint_utc\"] = sampled_tps.groupby(\"id_column\")[\n",
    "    \"timestamp_utc\"\n",
    "].transform(\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c87b44f-7dfb-4403-b5a1-ac7afc5514f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>raw_timepoint_id</th>\n",
       "      <th>demand_mw</th>\n",
       "      <th>study_timeframe_id</th>\n",
       "      <th>time_sample_id</th>\n",
       "      <th>id_column</th>\n",
       "      <th>period_id</th>\n",
       "      <th>date</th>\n",
       "      <th>days_in_month</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>days_in_year</th>\n",
       "      <th>first_timepoint_utc</th>\n",
       "      <th>last_timepoint_utc</th>\n",
       "      <th>no_days</th>\n",
       "      <th>name</th>\n",
       "      <th>num_timepoints</th>\n",
       "      <th>hours_per_tp</th>\n",
       "      <th>no_timeseries</th>\n",
       "      <th>scaling_to_period</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2030-01-09 00:00:00</td>\n",
       "      <td>175512</td>\n",
       "      <td>111044.495746</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2030-01-09 01:00:00</td>\n",
       "      <td>175513</td>\n",
       "      <td>116211.481894</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2030-01-09 02:00:00</td>\n",
       "      <td>175514</td>\n",
       "      <td>124045.126294</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2030-01-09 03:00:00</td>\n",
       "      <td>175515</td>\n",
       "      <td>126359.020794</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030-01-09 04:00:00</td>\n",
       "      <td>175516</td>\n",
       "      <td>127127.669994</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2030-01-09 05:00:00</td>\n",
       "      <td>175517</td>\n",
       "      <td>126186.413294</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2030-01-09 06:00:00</td>\n",
       "      <td>175518</td>\n",
       "      <td>124139.709928</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2030-01-09 07:00:00</td>\n",
       "      <td>175519</td>\n",
       "      <td>120053.721328</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2030-01-09 08:00:00</td>\n",
       "      <td>175520</td>\n",
       "      <td>117193.460828</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2030-01-09 09:00:00</td>\n",
       "      <td>175521</td>\n",
       "      <td>116633.712728</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2030-01-09 10:00:00</td>\n",
       "      <td>175522</td>\n",
       "      <td>115069.347828</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2030-01-09 11:00:00</td>\n",
       "      <td>175523</td>\n",
       "      <td>112679.214428</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>2030</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         timestamp_utc  raw_timepoint_id      demand_mw  study_timeframe_id  \\\n",
       "0  2030-01-09 00:00:00            175512  111044.495746                  39   \n",
       "1  2030-01-09 01:00:00            175513  116211.481894                  39   \n",
       "2  2030-01-09 02:00:00            175514  124045.126294                  39   \n",
       "3  2030-01-09 03:00:00            175515  126359.020794                  39   \n",
       "4  2030-01-09 04:00:00            175516  127127.669994                  39   \n",
       "5  2030-01-09 05:00:00            175517  126186.413294                  39   \n",
       "6  2030-01-09 06:00:00            175518  124139.709928                  39   \n",
       "7  2030-01-09 07:00:00            175519  120053.721328                  39   \n",
       "8  2030-01-09 08:00:00            175520  117193.460828                  39   \n",
       "9  2030-01-09 09:00:00            175521  116633.712728                  39   \n",
       "10 2030-01-09 10:00:00            175522  115069.347828                  39   \n",
       "11 2030-01-09 11:00:00            175523  112679.214428                  39   \n",
       "\n",
       "    time_sample_id     id_column  period_id        date  days_in_month  year  \\\n",
       "0               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "1               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "2               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "3               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "4               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "5               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "6               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "7               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "8               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "9               38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "10              38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "11              38  2030-01-09_P          1  2030-01-09             31  2030   \n",
       "\n",
       "    ...  days_in_year  first_timepoint_utc  last_timepoint_utc no_days  \\\n",
       "0   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "1   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "2   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "3   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "4   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "5   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "6   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "7   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "8   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "9   ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "10  ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "11  ...           365           2030-01-09 2030-01-09 23:00:00     1.0   \n",
       "\n",
       "       name num_timepoints  hours_per_tp  no_timeseries  scaling_to_period  \\\n",
       "0   2030-01             24             1             12                5.0   \n",
       "1   2030-01             24             1             12                5.0   \n",
       "2   2030-01             24             1             12                5.0   \n",
       "3   2030-01             24             1             12                5.0   \n",
       "4   2030-01             24             1             12                5.0   \n",
       "5   2030-01             24             1             12                5.0   \n",
       "6   2030-01             24             1             12                5.0   \n",
       "7   2030-01             24             1             12                5.0   \n",
       "8   2030-01             24             1             12                5.0   \n",
       "9   2030-01             24             1             12                5.0   \n",
       "10  2030-01             24             1             12                5.0   \n",
       "11  2030-01             24             1             12                5.0   \n",
       "\n",
       "    weight  \n",
       "0    120.0  \n",
       "1    120.0  \n",
       "2    120.0  \n",
       "3    120.0  \n",
       "4    120.0  \n",
       "5    120.0  \n",
       "6    120.0  \n",
       "7    120.0  \n",
       "8    120.0  \n",
       "9    120.0  \n",
       "10   120.0  \n",
       "11   120.0  \n",
       "\n",
       "[12 rows x 21 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling for peak day\n",
    "peak_days = sampled_tps[\"id_column\"].str.endswith(\"P\")\n",
    "median_days = sampled_tps[\"id_column\"].str.endswith(\"M\")\n",
    "\n",
    "# data.loc[peak_days, 'ts_scale_to_period'] = data['scale_to_period']\n",
    "\n",
    "# Duration of days for peak. This is for scaling purposes\n",
    "peak_duration = 1  # No days\n",
    "sampled_tps.loc[peak_days, \"no_days\"] = peak_duration\n",
    "sampled_tps.loc[median_days, \"no_days\"] = (\n",
    "    sampled_tps.loc[median_days, \"days_in_month\"] - peak_duration\n",
    ")\n",
    "\n",
    "sampled_tps.loc[:, \"name\"] = sampled_tps.timestamp_utc.dt.strftime(f\"%Y-%m\")\n",
    "sampled_tps.loc[:, \"num_timepoints\"] = sampled_tps.groupby(\"id_column\")[\n",
    "    \"raw_timepoint_id\"\n",
    "].transform(\"count\")\n",
    "sampled_tps.loc[:, \"hours_per_tp\"] = 1\n",
    "sampled_tps.loc[:, \"no_timeseries\"] = sampled_tps.groupby([\"period_id\"])[\n",
    "    \"name\"\n",
    "].transform(\"nunique\")\n",
    "\n",
    "\n",
    "# NOTE: If you need to scale the timepoints equally in the period just remove the\n",
    "# scaling of the number of days in the month.\n",
    "\n",
    "#scale to period (duration in years of each period) * (24 hours per day * number of days that each time series represents 1 for peak and 27/29/30 for median days) / duration in hours per time point (1) * number of time points per timeseries (24)\n",
    "sampled_tps.loc[:, \"scaling_to_period\"] = (\n",
    "    scale_to_period * (24 * sampled_tps[\"no_days\"])\n",
    ") / (\n",
    "    sampled_tps[\"hours_per_tp\"]\n",
    "    # sampled_tps[\"no_timeseries\"]\n",
    "    # * sampled_tps[\"hours_per_tp\"]\n",
    "    * sampled_tps[\"num_timepoints\"]\n",
    ")\n",
    "\n",
    "sampled_tps[\"weight\"] = (\n",
    "    sampled_tps[\"hours_per_tp\"]\n",
    "    * sampled_tps[\"num_timepoints\"]\n",
    "    # * sampled_tps[\"no_timeseries\"]\n",
    "    * sampled_tps[\"scaling_to_period\"]\n",
    ")\n",
    "sampled_tps[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ddff898-aaf4-4087-9d54-9d60fe01e840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sampled_timeseries_id</th>\n",
       "      <th>timestamp_utc</th>\n",
       "      <th>raw_timepoint_id</th>\n",
       "      <th>demand_mw</th>\n",
       "      <th>study_timeframe_id</th>\n",
       "      <th>time_sample_id</th>\n",
       "      <th>id_column</th>\n",
       "      <th>period_id</th>\n",
       "      <th>date</th>\n",
       "      <th>days_in_month</th>\n",
       "      <th>...</th>\n",
       "      <th>days_in_year</th>\n",
       "      <th>first_timepoint_utc</th>\n",
       "      <th>last_timepoint_utc</th>\n",
       "      <th>no_days</th>\n",
       "      <th>name</th>\n",
       "      <th>num_timepoints</th>\n",
       "      <th>hours_per_tp</th>\n",
       "      <th>no_timeseries</th>\n",
       "      <th>scaling_to_period</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>175512</td>\n",
       "      <td>111044.495746</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-09_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-09</td>\n",
       "      <td>2030-01-09 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-25</td>\n",
       "      <td>175896</td>\n",
       "      <td>115124.351479</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-01-25_M</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-25</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-01-25</td>\n",
       "      <td>2030-01-25 23:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2030-01</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2030-02-02</td>\n",
       "      <td>176088</td>\n",
       "      <td>117428.608220</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-02-02_M</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-02-02</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-02-02</td>\n",
       "      <td>2030-02-02 23:00:00</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2030-02</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>135.0</td>\n",
       "      <td>3240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2030-02-17</td>\n",
       "      <td>176448</td>\n",
       "      <td>119263.068202</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-02-17_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-02-17</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-02-17</td>\n",
       "      <td>2030-02-17 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-02</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2030-03-10</td>\n",
       "      <td>176952</td>\n",
       "      <td>116912.080629</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2030-03-10_P</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-03-10</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2030-03-10</td>\n",
       "      <td>2030-03-10 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2030-03</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>2050-10-13</td>\n",
       "      <td>357480</td>\n",
       "      <td>149139.650322</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2050-10-13_M</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-10-13</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2050-10-13</td>\n",
       "      <td>2050-10-13 23:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2050-10</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>2050-11-09</td>\n",
       "      <td>358128</td>\n",
       "      <td>150572.733850</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2050-11-09_M</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-11-09</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2050-11-09</td>\n",
       "      <td>2050-11-09 23:00:00</td>\n",
       "      <td>29.0</td>\n",
       "      <td>2050-11</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3480.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>2050-11-30</td>\n",
       "      <td>358632</td>\n",
       "      <td>162088.473590</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2050-11-30_P</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-11-30</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2050-11-30</td>\n",
       "      <td>2050-11-30 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2050-11</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>2050-12-14</td>\n",
       "      <td>358968</td>\n",
       "      <td>152694.834257</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2050-12-14_M</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-14</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2050-12-14</td>\n",
       "      <td>2050-12-14 23:00:00</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2050-12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>2050-12-20</td>\n",
       "      <td>359112</td>\n",
       "      <td>162857.087071</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>2050-12-20_P</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-20</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td>365</td>\n",
       "      <td>2050-12-20</td>\n",
       "      <td>2050-12-20 23:00:00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2050-12</td>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5.0</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sampled_timeseries_id timestamp_utc  raw_timepoint_id      demand_mw  \\\n",
       "0                        0    2030-01-09            175512  111044.495746   \n",
       "1                        1    2030-01-25            175896  115124.351479   \n",
       "2                        2    2030-02-02            176088  117428.608220   \n",
       "3                        3    2030-02-17            176448  119263.068202   \n",
       "4                        4    2030-03-10            176952  116912.080629   \n",
       "..                     ...           ...               ...            ...   \n",
       "115                    115    2050-10-13            357480  149139.650322   \n",
       "116                    116    2050-11-09            358128  150572.733850   \n",
       "117                    117    2050-11-30            358632  162088.473590   \n",
       "118                    118    2050-12-14            358968  152694.834257   \n",
       "119                    119    2050-12-20            359112  162857.087071   \n",
       "\n",
       "     study_timeframe_id  time_sample_id     id_column  period_id        date  \\\n",
       "0                    39              38  2030-01-09_P          1  2030-01-09   \n",
       "1                    39              38  2030-01-25_M          1  2030-01-25   \n",
       "2                    39              38  2030-02-02_M          1  2030-02-02   \n",
       "3                    39              38  2030-02-17_P          1  2030-02-17   \n",
       "4                    39              38  2030-03-10_P          1  2030-03-10   \n",
       "..                  ...             ...           ...        ...         ...   \n",
       "115                  39              38  2050-10-13_M          5  2050-10-13   \n",
       "116                  39              38  2050-11-09_M          5  2050-11-09   \n",
       "117                  39              38  2050-11-30_P          5  2050-11-30   \n",
       "118                  39              38  2050-12-14_M          5  2050-12-14   \n",
       "119                  39              38  2050-12-20_P          5  2050-12-20   \n",
       "\n",
       "     days_in_month  ...  days_in_year  first_timepoint_utc  \\\n",
       "0               31  ...           365           2030-01-09   \n",
       "1               31  ...           365           2030-01-25   \n",
       "2               28  ...           365           2030-02-02   \n",
       "3               28  ...           365           2030-02-17   \n",
       "4               31  ...           365           2030-03-10   \n",
       "..             ...  ...           ...                  ...   \n",
       "115             31  ...           365           2050-10-13   \n",
       "116             30  ...           365           2050-11-09   \n",
       "117             30  ...           365           2050-11-30   \n",
       "118             31  ...           365           2050-12-14   \n",
       "119             31  ...           365           2050-12-20   \n",
       "\n",
       "     last_timepoint_utc no_days     name  num_timepoints hours_per_tp  \\\n",
       "0   2030-01-09 23:00:00     1.0  2030-01              24            1   \n",
       "1   2030-01-25 23:00:00    30.0  2030-01              24            1   \n",
       "2   2030-02-02 23:00:00    27.0  2030-02              24            1   \n",
       "3   2030-02-17 23:00:00     1.0  2030-02              24            1   \n",
       "4   2030-03-10 23:00:00     1.0  2030-03              24            1   \n",
       "..                  ...     ...      ...             ...          ...   \n",
       "115 2050-10-13 23:00:00    30.0  2050-10              24            1   \n",
       "116 2050-11-09 23:00:00    29.0  2050-11              24            1   \n",
       "117 2050-11-30 23:00:00     1.0  2050-11              24            1   \n",
       "118 2050-12-14 23:00:00    30.0  2050-12              24            1   \n",
       "119 2050-12-20 23:00:00     1.0  2050-12              24            1   \n",
       "\n",
       "     no_timeseries  scaling_to_period  weight  \n",
       "0               12                5.0   120.0  \n",
       "1               12              150.0  3600.0  \n",
       "2               12              135.0  3240.0  \n",
       "3               12                5.0   120.0  \n",
       "4               12                5.0   120.0  \n",
       "..             ...                ...     ...  \n",
       "115             12              150.0  3600.0  \n",
       "116             12              145.0  3480.0  \n",
       "117             12                5.0   120.0  \n",
       "118             12              150.0  3600.0  \n",
       "119             12                5.0   120.0  \n",
       "\n",
       "[120 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_columns_ts = [\n",
    "    \"sampled_timeseries_id\",\n",
    "    \"study_timeframe_id\",\n",
    "    \"time_sample_id\",\n",
    "    \"period_id\",\n",
    "    \"id_column\",\n",
    "    \"hours_per_tp\",\n",
    "    \"num_timepoints\",\n",
    "    \"first_timepoint_utc\",\n",
    "    \"last_timepoint_utc\",\n",
    "    \"scaling_to_period\",\n",
    "]\n",
    "sampled_ts = (\n",
    "    sampled_tps.drop_duplicates([\"period_id\", \"id_column\"])\n",
    "    .reset_index(drop=True)\n",
    "    .copy()\n",
    ")\n",
    "sampled_ts.index = sampled_ts.index.rename(\"sampled_timeseries_id\")\n",
    "sampled_ts = sampled_ts.reset_index()\n",
    "sampled_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8009644-38cf-4bb3-b3a6-db9b1162d198",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "period_id\n",
       "1    8760.0\n",
       "2    8760.0\n",
       "3    8784.0\n",
       "4    8760.0\n",
       "5    8760.0\n",
       "Name: scaling_to_period, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify that the weights and scaling is correct!\n",
    "\n",
    "#sum of scaling factors * number of time points per time series * duration of time point / duration in years of each period, should add up to 8760 or 8784 for leap years\n",
    "sampled_ts.groupby(\"period_id\")[\"scaling_to_period\"].sum() * 24 * 1 / 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ab45866-bb78-48bd-874c-5bb490e57c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_timepoint_id</th>\n",
       "      <th>study_timeframe_id</th>\n",
       "      <th>time_sample_id</th>\n",
       "      <th>sampled_timeseries_id</th>\n",
       "      <th>period_id</th>\n",
       "      <th>timestamp_utc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>175512</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175513</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>175514</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>175515</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175516</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2030-01-09 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>359131</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-20 19:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>359132</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-20 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>359133</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-20 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>359134</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-20 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2879</th>\n",
       "      <td>359135</td>\n",
       "      <td>39</td>\n",
       "      <td>38</td>\n",
       "      <td>119</td>\n",
       "      <td>5</td>\n",
       "      <td>2050-12-20 23:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2880 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      raw_timepoint_id  study_timeframe_id  time_sample_id  \\\n",
       "0               175512                  39              38   \n",
       "1               175513                  39              38   \n",
       "2               175514                  39              38   \n",
       "3               175515                  39              38   \n",
       "4               175516                  39              38   \n",
       "...                ...                 ...             ...   \n",
       "2875            359131                  39              38   \n",
       "2876            359132                  39              38   \n",
       "2877            359133                  39              38   \n",
       "2878            359134                  39              38   \n",
       "2879            359135                  39              38   \n",
       "\n",
       "      sampled_timeseries_id  period_id       timestamp_utc  \n",
       "0                         0          1 2030-01-09 00:00:00  \n",
       "1                         0          1 2030-01-09 01:00:00  \n",
       "2                         0          1 2030-01-09 02:00:00  \n",
       "3                         0          1 2030-01-09 03:00:00  \n",
       "4                         0          1 2030-01-09 04:00:00  \n",
       "...                     ...        ...                 ...  \n",
       "2875                    119          5 2050-12-20 19:00:00  \n",
       "2876                    119          5 2050-12-20 20:00:00  \n",
       "2877                    119          5 2050-12-20 21:00:00  \n",
       "2878                    119          5 2050-12-20 22:00:00  \n",
       "2879                    119          5 2050-12-20 23:00:00  \n",
       "\n",
       "[2880 rows x 6 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_columns_tps = [\n",
    "    \"raw_timepoint_id\",\n",
    "    \"study_timeframe_id\",\n",
    "    \"time_sample_id\",\n",
    "    \"sampled_timeseries_id\",\n",
    "    \"period_id\",\n",
    "    \"timestamp_utc\",\n",
    "]\n",
    "\n",
    "sampled_tps_tms = pd.merge(\n",
    "    sampled_tps,\n",
    "    sampled_ts[[\"sampled_timeseries_id\", \"period_id\", \"id_column\"]],\n",
    "    how=\"right\",\n",
    "    on=[\"period_id\", \"id_column\"],\n",
    ")\n",
    "# sampled_tps = sampled_tps_tms[output_columns_tps]\n",
    "sampled_tps_tms[output_columns_tps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b74b1c74-0755-47b3-b767-7d959b13af05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ study_timeframe: \n",
      "|  Inserting new data to DB.\n"
     ]
    }
   ],
   "source": [
    "table_name = \"study_timeframe\"\n",
    "columns = [\"study_timeframe_id\", \"name\", \"description\"]\n",
    "id_column = \"study_timeframe_id\"\n",
    "\n",
    "# TODO: Maybe find a better way to do this on a general function for all the tables.\n",
    "# This works for the moment for each table\n",
    "values = [(study_id, study_name, study_description)]\n",
    "\n",
    "# Calling insert function\n",
    "insert_to_db(\n",
    "    table_name,\n",
    "    columns,\n",
    "    values,\n",
    "    schema=SCHEMA,\n",
    "    id_column=id_column,\n",
    "    id_var=study_id,\n",
    "    db_conn=db_conn,\n",
    "    overwrite=OVERWRITE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b044768-1570-4566-8c86-5f924aee269b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ period: \n",
      "|  Inserting new data to DB.\n"
     ]
    }
   ],
   "source": [
    "insert_to_db(\n",
    "    table_name=\"period\",\n",
    "    columns=[\n",
    "        \"study_timeframe_id\",\n",
    "        \"period_id\",\n",
    "        \"start_year\",\n",
    "        \"label\",\n",
    "        \"length_yrs\",\n",
    "        \"end_year\",\n",
    "    ],\n",
    "    values=period_values,\n",
    "    schema=SCHEMA,\n",
    "    id_column=\"study_timeframe_id\",\n",
    "    id_var=study_id,\n",
    "    db_conn=db_conn,\n",
    "    overwrite=OVERWRITE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "89c64e33-d380-4849-8b68-6c3580de03ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ time_sample: \n",
      "|  Inserting new data to DB.\n"
     ]
    }
   ],
   "source": [
    "values = [(time_sample_id, study_id, ts_name, method, ts_description)]\n",
    "\n",
    "insert_to_db(\n",
    "    table_name=\"time_sample\",\n",
    "    columns=[\n",
    "        \"time_sample_id\",\n",
    "        \"study_timeframe_id\",\n",
    "        \"name\",\n",
    "        \"method\",\n",
    "        \"description\",\n",
    "    ],\n",
    "    schema=SCHEMA,\n",
    "    values=values,\n",
    "    id_column=\"time_sample_id\",\n",
    "    id_var=time_sample_id,\n",
    "    db_conn=db_conn,\n",
    "    overwrite=OVERWRITE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a8e397e5-65c3-4ffd-b389-b2c7f37e628f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+ sampled_timeseries: \n",
      "|  Inserting new data to DB.\n",
      "+ sampled_timepoint: \n",
      "|  Inserting new data to DB.\n"
     ]
    }
   ],
   "source": [
    "tps_table_name = \"sampled_timepoint\"\n",
    "ts_table_name = \"sampled_timeseries\"\n",
    "\n",
    "id_column = \"time_sample_id\"\n",
    "\n",
    "tps_to_db = sampled_tps_tms[output_columns_tps]\n",
    "ts_to_db = sampled_ts[output_columns_ts].rename(columns={\"id_column\": \"name\"})\n",
    "\n",
    "\n",
    "insert_to_db(\n",
    "    ts_table_name,\n",
    "    ts_to_db.columns,\n",
    "    [tuple(r) for r in ts_to_db.to_numpy()],\n",
    "    id_column=id_column,\n",
    "    schema=SCHEMA,\n",
    "    id_var=time_sample_id,\n",
    "    db_conn=db_conn,\n",
    "    overwrite=OVERWRITE,\n",
    ")\n",
    "insert_to_db(\n",
    "    tps_table_name,\n",
    "    tps_to_db.columns,\n",
    "    [tuple(r) for r in tps_to_db.to_numpy()],\n",
    "    id_column=id_column,\n",
    "    schema=SCHEMA,\n",
    "    id_var=time_sample_id,\n",
    "    db_conn=db_conn,\n",
    "    overwrite=OVERWRITE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71beb12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
